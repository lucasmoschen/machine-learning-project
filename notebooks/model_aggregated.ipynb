{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48208abc-6e63-45e0-a93a-8cb338867d67",
   "metadata": {},
   "source": [
    "# Models for ozone \n",
    "\n",
    "In this notebook, we develop the models for the transformed dataset considering the exogenous variable to be the **Ozone**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28bf549-2adb-4ae3-9f5b-a497e748cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c676c817-f2fa-4705-b74c-1a0f9facfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f69d51-1dee-4c7b-ab0c-737ceae9a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from utilities import Utilities\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet, LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# others\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "from scipy.stats import jarque_bera\n",
    "\n",
    "# R packages\n",
    "import rpy2\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import FloatVector, r\n",
    "\n",
    "norm = importr(\"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38338f3f-e09c-4dda-81bd-d2cc34ebb51e",
   "metadata": {},
   "source": [
    "## Definitions for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c66750-99d3-4bbe-bfb2-d9f5ef7f84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local folder\n",
    "IMAGES_FOLDER = \"../notes/images/\"\n",
    "# For Google colab\n",
    "#IMAGES_FOLDER = \"drive/MyDrive/Arquivos Acadêmicos/Disciplinas FGV/Machine Learning/images/\"\n",
    "\n",
    "# For local folder\n",
    "location = \"../data/\"\n",
    "# For Google colab\n",
    "#location = \"drive/MyDrive/Arquivos Acadêmicos/Disciplinas FGV/Machine Learning/\"\n",
    "\n",
    "sns.set()\n",
    "\n",
    "pd.set_option('precision', 3)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "utility = Utilities()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52349d4-48f6-45cb-8597-b07b0df457e4",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44b8227-3a40-43d9-b9dc-f33c9689be4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>CodNum</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Chuva</th>\n",
       "      <th>Pres</th>\n",
       "      <th>RS</th>\n",
       "      <th>Temp</th>\n",
       "      <th>...</th>\n",
       "      <th>CO_lag24</th>\n",
       "      <th>CO_MA24</th>\n",
       "      <th>O3_lag1</th>\n",
       "      <th>O3_lag2</th>\n",
       "      <th>O3_lag24</th>\n",
       "      <th>O3_MA24</th>\n",
       "      <th>PM10_lag1</th>\n",
       "      <th>PM10_lag2</th>\n",
       "      <th>PM10_lag24</th>\n",
       "      <th>PM10_MA24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-22.965</td>\n",
       "      <td>-43.180</td>\n",
       "      <td>3.617</td>\n",
       "      <td>-1.530</td>\n",
       "      <td>-1.128</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-1.190</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-22.898</td>\n",
       "      <td>-43.222</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-1.513</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>0.560</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.678</td>\n",
       "      <td>-1.232</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-1.858</td>\n",
       "      <td>-1.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-22.908</td>\n",
       "      <td>-43.178</td>\n",
       "      <td>3.617</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-1.617</td>\n",
       "      <td>-1.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "      <td>3.617</td>\n",
       "      <td>-1.909</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-1.283</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-1.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-22.898</td>\n",
       "      <td>-43.222</td>\n",
       "      <td>3.617</td>\n",
       "      <td>-1.658</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.548</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.591</td>\n",
       "      <td>-1.206</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-1.136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  CodNum     Lat     Lon  Chuva   Pres     RS   Temp  ...  \\\n",
       "0  2011      1    2       1 -22.965 -43.180  3.617 -1.530 -1.128 -0.140  ...   \n",
       "1  2011      1    2       7 -22.898 -43.222 -0.272 -1.513 -0.565  0.560  ...   \n",
       "2  2011      1    2       3 -22.908 -43.178  3.617 -1.557 -0.720 -0.470  ...   \n",
       "3  2011      1    2       8 -22.925 -43.233  3.617 -1.909 -0.194 -1.068  ...   \n",
       "4  2011      1    2       7 -22.898 -43.222  3.617 -1.658 -0.567  0.548  ...   \n",
       "\n",
       "   CO_lag24  CO_MA24  O3_lag1  O3_lag2  O3_lag24  O3_MA24  PM10_lag1  \\\n",
       "0    -0.763   -0.936   -0.738   -0.543    -1.190   -0.365      0.101   \n",
       "1    -1.678   -1.232   -0.612   -0.997    -0.724   -0.187     -0.307   \n",
       "2    -0.634   -0.166   -0.211   -0.717    -0.169   -0.027     -0.677   \n",
       "3    -0.897   -1.283   -0.267   -0.184    -1.028    0.274     -0.773   \n",
       "4    -1.591   -1.206   -1.300   -0.612    -1.099   -0.204     -0.484   \n",
       "\n",
       "   PM10_lag2  PM10_lag24  PM10_MA24  \n",
       "0      0.078       0.087      0.082  \n",
       "1     -0.967      -1.858     -1.136  \n",
       "2     -0.677      -1.617     -1.141  \n",
       "3     -0.583       0.495     -1.061  \n",
       "4     -0.307      -0.967     -1.136  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_data = pd.read_csv(location + \"RiodeJaneiro_MonitorAr_hourly_p3.csv\", index_col = 0)\n",
    "air_data.weekend = air_data.weekend.astype(int)\n",
    "air_data = air_data.reset_index().drop(columns=\"index\")\n",
    "air_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b37e0-8ef4-4bf2-806f-253a9ef58d3a",
   "metadata": {},
   "source": [
    "## Inverse Power Transformation \n",
    "\n",
    "Just for future transformations on ozone data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463ee4d1-d4a0-4d9d-9c81-d18f4544e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data_ = pd.read_csv(location + \"RiodeJaneiro_MonitorAr_hourly_p2.csv\", index_col = 0)\n",
    "\n",
    "gases = ['CO', 'O3', 'PM10']\n",
    "\n",
    "pt_gases = {key: PowerTransformer(method = 'yeo-johnson', \n",
    "                                  standardize=True).fit(air_data_[[key]]) for key in gases}\n",
    "\n",
    "del air_data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fce8e1-803f-4464-9a4a-574c657bab47",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60acefbb-d182-4718-89e8-0ffbda84e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = air_data[air_data.train].drop(columns='train')\n",
    "df_test = air_data[~air_data.train].drop(columns='train')\n",
    "\n",
    "x_train = df_train.drop(columns=[\"O3\", 'CO', 'PM10', 'aiq', 'Lat', 'Lon'])\n",
    "x_test = df_test.drop(columns=[\"O3\", 'CO', 'PM10', 'aiq', 'Lat', 'Lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d34ef4-0f21-49d6-a6e2-1d963df2c6a1",
   "metadata": {},
   "source": [
    "## Models for each gas and each station \n",
    "\n",
    "Now we are going to apply the models for each of the best models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f44f42-71f9-4b86-b923-3af137f4b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "best_features_o3 = ['year O3_lag1', 'RS', 'RS hour_cos', 'year Vel_Vento', \n",
    "                    'O3_lag2', 'year O3_MA24', 'hour_cos PM10_lag1', 'RS Temp', \n",
    "                    'RS O3_lag2', 'O3_lag1^2']\n",
    "best_features_co = ['CO_lag1', 'hour_sin^2', 'CO_lag24', 'hour_cos', 'year Vel_Vento', \n",
    "                    'CO_MA24', 'RS PM10_lag1', 'CO_lag2', 'Vel_Vento^2']\n",
    "best_features_pm10 = ['PM10_lag1', 'year PM10_MA24', 'hour_cos', 'O3_lag1', \n",
    "                      'year O3_lag2', 'hour_sin hour_cos', 'year Temp', 'RS O3_lag2', 'O3_lag1^2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf0be1-3aa3-4d76-a131-5cf70f5cd598",
   "metadata": {},
   "source": [
    "## Ozone models \n",
    "\n",
    "For the ozone, we test SVR with kernels RBF/linear and best features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc92a2-149b-4e3d-b5e0-fa79f59a1b32",
   "metadata": {},
   "source": [
    "### SVR with RBF Kernel and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f21412c-9f40-4e8a-8ffa-b57f65b5fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = make_pipeline(StandardScaler(), \n",
    "                    SVR(kernel = 'rbf', \n",
    "                        degree = 2, \n",
    "                        epsilon = 0.2, \n",
    "                        C = 1.0,\n",
    "                        max_iter = 200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d75efcb-427e-43bc-8a0e-fcdf6bfe2b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [23:36<00:00, 177.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_o3 = df_train[df_train.CodNum == station].O3\n",
    "    y_test_o3 = df_test[df_test.CodNum == station].O3\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    svr.fit(x_train_SP_poly[best_features_o3], y_train_o3)\n",
    "    \n",
    "    y_pred = svr.predict(x_test_SP_poly[best_features_o3])\n",
    "\n",
    "    y_train_pred = svr.predict(x_train_SP_poly[best_features_o3])\n",
    "\n",
    "    r2_train = r2_score(y_train_o3, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_o3, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_o3, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_o3, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_o3, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_o3, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"O3\", station, \"svr_rbf_best_features\", \n",
    "                         {'epsilon': 0.2, 'C': 1.0},    \n",
    "                          r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c03ad6-859d-47e1-bb00-0780cdca8019",
   "metadata": {},
   "source": [
    "### SVR with Linear Kernel and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2560ea11-d80b-4c55-808c-0402e1552560",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_linear = make_pipeline(StandardScaler(), \n",
    "                           LinearSVR(epsilon = 0.2, \n",
    "                                     C = 1.0,\n",
    "                                     max_iter = 200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6778093-ca52-413c-90dd-656a625107e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:44<00:00,  5.61s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_o3 = df_train[df_train.CodNum == station].O3\n",
    "    y_test_o3 = df_test[df_test.CodNum == station].O3\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    svr_linear.fit(x_train_SP_poly[best_features_o3], y_train_o3)\n",
    "    \n",
    "    y_pred = svr_linear.predict(x_test_SP_poly[best_features_o3])\n",
    "\n",
    "    y_train_pred = svr_linear.predict(x_train_SP_poly[best_features_o3])\n",
    "\n",
    "    r2_train = r2_score(y_train_o3, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_o3, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_o3, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_o3, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_o3, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_o3, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"O3\", station, \"svr_linear_best_features\", \n",
    "                         {'epsilon': 0.2, 'C': 1.0},    \n",
    "                          r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07e9ed-2f6a-467f-be05-62222d4926c6",
   "metadata": {},
   "source": [
    "### Linear regression with EM and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06283105-4057-43e0-a14a-a536c3d2a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:15<01:47, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:30<01:29, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:44<01:14, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:58<00:58, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...62...63...64...65...66...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [01:13<00:43, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [01:27<00:28, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [01:41<00:14, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...62...63...64...65...66...67...68...69...70...71...72...73...74...75...76...77...78...79...80...81...82...83...84...85...86...87...88...89...90...91...92...93...94...95...96...97...98...99...100...101...102...103...104...105...106...107...108...109...110...111...112...113...114...115...116...117...118...119...120...121...122...123...124...125...126...127...128...129...130...131...132...133...134...135...136...137...138...139...140...141...142...143...144...145...146...147...148...149...150...151...152...153...154...155...156...157...158...159...160...161...162...163...164...165...166...167...168...169...170...171...172...173...174...175...176...177...178...179...180...181...182...183...184...185...186...187...188...189...190...191...192...193...194...195...196...197...198...199...200...201...202...203...204...205...206...207...208...209...210...211...212...213...214...215...216...217...218...219...220...221...222...223...224...225...226...227...228...229...230...231...232...233...234...235...236...237...238...239...240...241...242...243...244...245...246...247...248...249...250...251...252...253...254...255...256...257...258...259...260...261...262...263...264...265...266...267...268...269...270...271...272...273...274...275...276...277...278...279...280...281...282...283...284...285...286...287...288...289...290...291...292...293...294...295...296...297...298...299...300...301...302...303...304...305...306...307...308...309...310...311...312...313...314...315...316...317...318...319...320...321...322...323...324...325...326...327...328...329...330...331...332...333...334...335...336...337...338...339...340...341...342...343...344...345...346...347...348...349...350...351...352...353...354...355...356...357...358...359...360...361...362...363...364...365...366...367...368...369...370...371...372...373...374...375...376...377...378...379...380...381...382...383...384...385...386...387...388...389...390...391...392...393...394...395...396...397...398...399...400...401...402...403...404...405...406...407...408...409...410...411...412...413...414...415...416...417...418...419...420...421...422...423...424...425...426...427...428...429...430...431...432...433...434...435...436...437...438...439...440...441...442...443...444...445...446...447...448...449...450...451...452...453...454...455...456...457...458...459...460...461...462...463...464...465...466...467...468...469...470...471...472...473...474...475...476...477...478...479...480...481...482...483...484...485...486...487...488...489...490...491...492...493...494...495...496...497...498...499...500...501...502...503...504...505...506...507...508...509...510...511...512...513...514...515...516...517...518...519...520...521...522...523...524...525...526...527...528...529...530...531...532...533...534...535...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:32<00:00, 19.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)):\n",
    "        \n",
    "    # Dataset with imputed data\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_o3 = df_train[df_train.CodNum == station].O3\n",
    "    y_test_o3 = df_test[df_test.CodNum == station].O3\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    # Dataset with missing values\n",
    "    df = utility.linear_regression_em_preparation(location, gas_name='O3', loc = station)\n",
    "    df_2 = pd.DataFrame()\n",
    "    # Adding polynomial and interactions terms\n",
    "    for feat in best_features_o3: \n",
    "        feats = feat.split()\n",
    "        if len(feats) == 2: \n",
    "            df_2[feat] = df[feats[0]]*df_train[feats[1]]\n",
    "        elif feats[0][-2] == '^': \n",
    "            df_2[feat] = df[feats[0][:-2]]**2\n",
    "        else: \n",
    "            df_2[feat] = df[feats[0]]\n",
    "    df_2['O3'] = df['O3']\n",
    "\n",
    "    X_r = FloatVector(df_2.values.flatten())\n",
    "    m = r['matrix'](X_r, ncol = df_2.shape[1], byrow = True)\n",
    "\n",
    "    s = norm.prelim_norm(m)  \n",
    "    theta = norm.em_norm(s)\n",
    "    params = norm.getparam_norm(s,theta,corr=False)\n",
    "    params = dict(zip(params.names, map(np.array,list(params))))\n",
    "\n",
    "    mu_y = params['mu'][-1]\n",
    "    mu_X = params['mu'][:-1].reshape(-1,1)\n",
    "\n",
    "    Sigma_XX = params['sigma'][:-1,:-1]\n",
    "    Sigma_yX = params['sigma'][-1,:-1].reshape(1,-1)\n",
    "    Sigma_Xy = params['sigma'][:-1,-1].reshape(-1,1)\n",
    "    Sigma_yy = params['sigma'][-1,-1]\n",
    "\n",
    "    inv_Sigma_XX = np.linalg.inv(Sigma_XX)\n",
    "\n",
    "    beta = np.hstack([mu_y - Sigma_yX@inv_Sigma_XX@mu_X, Sigma_yX@inv_Sigma_XX]).reshape(-1,1)\n",
    "\n",
    "    y_pred = x_test_SP_poly[best_features_o3]@beta[1:] + beta[0]\n",
    "\n",
    "    y_train_pred = x_train_SP_poly[best_features_o3]@beta[1:] + beta[0]\n",
    "\n",
    "    r2_train = r2_score(y_train_o3, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_o3, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_o3, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_o3, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_o3, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_o3, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"O3\", station, \"linear_regression_em_best_features\", \n",
    "                         {},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c9ff5-21fe-4799-b3ad-d28a5c9077db",
   "metadata": {},
   "source": [
    "## CO Models\n",
    "\n",
    "For the carbon monoxide, we test Random Forest and SVR with linear kernel, both with best features. Pedra da Guaratiba (6) does not measure this quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87354f-5181-474e-8f4d-9e9341360f4f",
   "metadata": {},
   "source": [
    "### Random Forest with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7700f3d7-00a2-41ec-9eef-dac983162ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestRegressor(n_estimators = 500, \n",
    "                                    criterion = 'mse', \n",
    "                                    min_samples_split = 5, \n",
    "                                    max_features = 'sqrt',\n",
    "                                    ccp_alpha = 0.0,\n",
    "                                    n_jobs = 2,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb141c1-b193-4582-a8e1-942eb6ea3a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:50<00:00, 28.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "    \n",
    "    if station == 6: continue\n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_co = df_train[df_train.CodNum == station].CO\n",
    "    y_test_co = df_test[df_test.CodNum == station].CO\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    rand_forest.fit(x_train_SP_poly[best_features_co], y_train_co)\n",
    "    \n",
    "    y_pred = rand_forest.predict(x_test_SP_poly[best_features_co])\n",
    "\n",
    "    y_train_pred = rand_forest.predict(x_train_SP_poly[best_features_co])\n",
    "\n",
    "    r2_train = r2_score(y_train_co, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_co, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_co, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_co, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_co, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_co, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"CO\", station, \"random_forest_best_features\", \n",
    "                         {'s': 5, 'c': 0, 'B': 500},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d10f73-3ce4-4fb1-8dca-baa0415d40fb",
   "metadata": {},
   "source": [
    "### SVR with linear kernel and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2318768b-a2d4-43a8-9895-e0d5a2b43a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = make_pipeline(StandardScaler(), \n",
    "                    LinearSVR(epsilon = 0.2, \n",
    "                              C = 0.01,\n",
    "                              max_iter = 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6b647f7-a520-4226-8451-44ce7780a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "    \n",
    "    if station == 6: continue\n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_co = df_train[df_train.CodNum == station].CO\n",
    "    y_test_co = df_test[df_test.CodNum == station].CO\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    svr.fit(x_train_SP_poly[best_features_co], y_train_co)\n",
    "    \n",
    "    y_pred = svr.predict(x_test_SP_poly[best_features_co])\n",
    "\n",
    "    y_train_pred = svr.predict(x_train_SP_poly[best_features_co])\n",
    "\n",
    "    r2_train = r2_score(y_train_co, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_co, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_co, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_co, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_co, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_co, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"CO\", station, \"svr_linear_best_features\", \n",
    "                         {'epsilon': 0.2, 'C': 0.01},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643119e7-57dc-4ca5-85e5-de177c32e541",
   "metadata": {},
   "source": [
    "### Linear regression with EM imputation and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9cfd6d3-7448-4e8a-9d42-f21069a0e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:09<01:07,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:20<01:01, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:30<00:51, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:41<00:42, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:51<00:30, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [01:01<00:07,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations of EM: \n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...62...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:11<00:00,  8.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)):\n",
    "    \n",
    "    if station == 6: continue\n",
    "    \n",
    "    # Dataset with imputed data\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_co = df_train[df_train.CodNum == station].CO\n",
    "    y_test_co = df_test[df_test.CodNum == station].CO\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    # Dataset with missing values\n",
    "    df = utility.linear_regression_em_preparation(location, gas_name='CO', loc = station)\n",
    "    df_2 = pd.DataFrame()\n",
    "    # Adding polynomial and interactions terms\n",
    "    for feat in best_features_co: \n",
    "        feats = feat.split()\n",
    "        if len(feats) == 2: \n",
    "            df_2[feat] = df[feats[0]]*df_train[feats[1]]\n",
    "        elif feats[0][-2] == '^': \n",
    "            df_2[feat] = df[feats[0][:-2]]**2\n",
    "        else: \n",
    "            df_2[feat] = df[feats[0]]\n",
    "    df_2['CO'] = df['CO']\n",
    "\n",
    "    X_r = FloatVector(df_2.values.flatten())\n",
    "    m = r['matrix'](X_r, ncol = df_2.shape[1], byrow = True)\n",
    "\n",
    "    s = norm.prelim_norm(m)  \n",
    "    theta = norm.em_norm(s)\n",
    "    params = norm.getparam_norm(s,theta,corr=False)\n",
    "    params = dict(zip(params.names, map(np.array,list(params))))\n",
    "\n",
    "    mu_y = params['mu'][-1]\n",
    "    mu_X = params['mu'][:-1].reshape(-1,1)\n",
    "\n",
    "    Sigma_XX = params['sigma'][:-1,:-1]\n",
    "    Sigma_yX = params['sigma'][-1,:-1].reshape(1,-1)\n",
    "    Sigma_Xy = params['sigma'][:-1,-1].reshape(-1,1)\n",
    "    Sigma_yy = params['sigma'][-1,-1]\n",
    "\n",
    "    inv_Sigma_XX = np.linalg.inv(Sigma_XX)\n",
    "\n",
    "    beta = np.hstack([mu_y - Sigma_yX@inv_Sigma_XX@mu_X, Sigma_yX@inv_Sigma_XX]).reshape(-1,1)\n",
    "\n",
    "    y_pred = x_test_SP_poly[best_features_co]@beta[1:] + beta[0]\n",
    "\n",
    "    y_train_pred = x_train_SP_poly[best_features_co]@beta[1:] + beta[0]\n",
    "\n",
    "    r2_train = r2_score(y_train_co, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_co, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_co, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_co, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_co, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_co, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"CO\", station, \"linear_regression_em_best_features\", \n",
    "                         {},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8f9be-596c-4242-9ab2-21c4758fd631",
   "metadata": {},
   "source": [
    "## PM10 Models\n",
    "\n",
    "For the particulate matter, we test Random Forest and SVR with linear kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfee357-2d3d-4125-b8ad-23c0427a0047",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "997ccb2a-ac48-4026-b765-ebd65a56c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestRegressor(n_estimators = 500, \n",
    "                                    criterion = 'mse', \n",
    "                                    min_samples_split = 10, \n",
    "                                    max_features = 'sqrt',\n",
    "                                    ccp_alpha = 0.0,\n",
    "                                    n_jobs = 2,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ddfb72-8f81-4fce-8c64-d0258a6ff56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:33<00:00, 49.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_pm10 = df_train[df_train.CodNum == station].PM10\n",
    "    y_test_pm10 = df_test[df_test.CodNum == station].PM10\n",
    "\n",
    "    rand_forest.fit(x_train_SP, y_train_pm10)\n",
    "    \n",
    "    y_pred = rand_forest.predict(x_test_SP)\n",
    "\n",
    "    y_train_pred = rand_forest.predict(x_train_SP)\n",
    "\n",
    "    r2_train = r2_score(y_train_pm10, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_pm10, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_pm10, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_pm10, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_pm10, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_pm10, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"PM10\", station, \"random_forest\", \n",
    "                         {'s': 10, 'c': 0.0, 'B': 100},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec3c96-0d9a-4006-adbe-7872fd22ed88",
   "metadata": {},
   "source": [
    "### SVR Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37effa2a-6e7a-4659-9fe6-bd2c680efad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = make_pipeline(StandardScaler(), \n",
    "                    LinearSVR(epsilon = 0.01, \n",
    "                              C = 0.1,\n",
    "                              max_iter = 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67973af1-167a-4e9d-89e1-d35803837e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:11<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_pm10 = df_train[df_train.CodNum == station].PM10\n",
    "    y_test_pm10 = df_test[df_test.CodNum == station].PM10\n",
    "\n",
    "    svr.fit(x_train_SP, y_train_pm10)\n",
    "    \n",
    "    y_pred = svr.predict(x_test_SP)\n",
    "\n",
    "    y_train_pred = svr.predict(x_train_SP)\n",
    "\n",
    "    r2_train = r2_score(y_train_pm10, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_pm10, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_pm10, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_pm10, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_pm10, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_pm10, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"PM10\", station, \"svr_linear\", \n",
    "                         {'epsilon': 0.01, 'C': 0.1},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230fbc93-d256-4784-b567-0ebbd68c4eb4",
   "metadata": {},
   "source": [
    "### SVR with RBF Kernel and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d756565-8447-48a3-a517-98615f4327ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = make_pipeline(StandardScaler(), \n",
    "                    SVR(kernel = 'rbf', \n",
    "                        degree = 2, \n",
    "                        epsilon = 0.01, \n",
    "                        C = 0.1,\n",
    "                        max_iter = 200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5a875cf-d4b9-4826-bc17-7cc3ffd497dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [43:09<00:00, 323.66s/it]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(range(1,9)): \n",
    "\n",
    "    x_train_SP = x_train[x_train.CodNum == station].drop(columns=\"CodNum\")\n",
    "    x_test_SP = x_test[x_test.CodNum == station].drop(columns=\"CodNum\")\n",
    "\n",
    "    y_train_pm10 = df_train[df_train.CodNum == station].PM10\n",
    "    y_test_pm10 = df_test[df_test.CodNum == station].PM10\n",
    "    \n",
    "    x_train_SP_poly = pd.DataFrame(poly.fit_transform(x_train_SP), \n",
    "                                   columns = poly.get_feature_names(x_train_SP.columns), \n",
    "                                   index = x_train_SP.index)\n",
    "    x_test_SP_poly = pd.DataFrame(poly.fit_transform(x_test_SP), \n",
    "                                  columns = poly.get_feature_names(x_test_SP.columns),\n",
    "                                  index = x_test_SP.index)\n",
    "\n",
    "    svr.fit(x_train_SP_poly[best_features_pm10], y_train_pm10)\n",
    "    \n",
    "    y_pred = svr.predict(x_test_SP_poly[best_features_pm10])\n",
    "\n",
    "    y_train_pred = svr.predict(x_train_SP_poly[best_features_pm10])\n",
    "\n",
    "    r2_train = r2_score(y_train_pm10, y_train_pred)\n",
    "    r2_test  = r2_score(y_test_pm10, y_pred)\n",
    "    mae_train = mean_absolute_error(y_train_pm10, y_train_pred)\n",
    "    mae_test  = mean_absolute_error(y_test_pm10, y_pred)\n",
    "    rmse_train = mean_squared_error(y_train_pm10, y_train_pred, squared = False)\n",
    "    rmse_test  = mean_squared_error(y_test_pm10, y_pred, squared = False)\n",
    "\n",
    "    utility.save_metrics(\"PM10\", station, \"svr_rbf_best_features\", \n",
    "                         {'epsilon': 0.01, 'C': 0.1},    \n",
    "                         r2_train, r2_test, mae_train, mae_test, rmse_train, rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374b7db-7719-4273-8378-a908f5496ca5",
   "metadata": {},
   "source": [
    "## Table aggregating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f1a03c1-008f-4824-a2b0-8139a8a58d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('../data/models.json', 'r') as f: \n",
    "    models = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4969b258-a5f4-4133-8ef1-edc5ff64853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "for i in models.keys():\n",
    "    df_models = df_models.append(pd.json_normalize(models[i]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1b6c7-daf4-460a-b6ca-038884a4b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
